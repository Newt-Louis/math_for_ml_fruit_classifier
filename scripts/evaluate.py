import torch
from torchvision import datasets, transforms, models
from pathlib import Path
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from tqdm import tqdm
import numpy as np

# -------- Paths (C·∫≠p nh·∫≠t cho kh·ªõp v·ªõi train.py) --------
BASE = Path(__file__).resolve().parent.parent
MODEL_DIR = BASE / "models"
BEST_MODEL_PATH = MODEL_DIR / "fruit_classifier_best.pt"
HISTORY_PATH = MODEL_DIR / "history.json"
LABELS_PATH = MODEL_DIR / "labels.json"
TEST_DIR = BASE / "data" / "raw" / "fruits-360_100x100" / "fruits-360" / "Test"

# -------- Load Data and Model --------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load labels
with open(LABELS_PATH, 'r') as f:
    classes = json.load(f)

# Load history
with open(HISTORY_PATH, 'r') as f:
    history = json.load(f)

# [QUAN TR·ªåNG] Ph√©p transform cho t·∫≠p test/ƒë√°nh gi√° PH·∫¢I gi·ªëng h·ªát l√∫c training
eval_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load model
model = models.resnet18(weights=None)
model.fc = torch.nn.Linear(model.fc.in_features, len(classes))
model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))
model.to(device)
model.eval()


# -------- 1. V·∫Ω ƒë·ªì th·ªã Loss v√† Accuracy --------
def plot_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # ƒê·ªì th·ªã Loss
    ax1.plot(history['train_loss'], label='Training Loss')
    ax1.plot(history['val_loss'], label='Validation Loss')
    ax1.set_title('Training & Validation Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True)

    # ƒê·ªì th·ªã Accuracy
    train_acc_percent = [a * 100 for a in history['train_acc']]
    val_acc_percent = [a * 100 for a in history['val_acc']]
    ax2.plot(train_acc_percent, label='Training Accuracy')
    ax2.plot(val_acc_percent, label='Validation Accuracy')
    ax2.set_title('Training & Validation Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')  # Hi·ªÉn th·ªã theo %
    ax2.legend()
    ax2.grid(True)

    plt.suptitle('Model Training History')
    plt.show()

    best_epoch = np.argmax(history['val_acc'])
    best_acc = history['val_acc'][best_epoch]
    print(f"üöÄ Hi·ªáu su·∫•t t·ªët nh·∫•t tr√™n t·∫≠p validation: {best_acc * 100:.2f}% t·∫°i Epoch th·ª© {best_epoch + 1}")


# -------- 2. T·∫°o ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix) --------
def generate_confusion_matrix():
    print("\nüìä ƒêang t·∫°o ma tr·∫≠n nh·∫ßm l·∫´n...")
    test_ds = datasets.ImageFolder(TEST_DIR, transform=eval_transform)  # S·ª≠ d·ª•ng eval_transform
    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)

    all_preds = []
    all_labels = []
    with torch.no_grad():
        for x, y in tqdm(test_loader, desc="Generating Confusion Matrix"):
            x = x.to(device)
            out = model(x)
            _, pred = torch.max(out, 1)
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(y.numpy())

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(25, 25))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ hi·ªÉn th·ªã r√µ c√°c nh√£n
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')
    plt.xlabel('Predicted Label', fontsize=14)
    plt.ylabel('True Label', fontsize=14)
    plt.title('Confusion Matrix', fontsize=16)
    plt.xticks(rotation=90)  # Xoay nh√£n tr·ª•c x
    plt.yticks(rotation=0)
    plt.tight_layout()  # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh layout
    plt.show()


# -------- 3. Hi·ªÉn th·ªã v√≠ d·ª• d·ª± ƒëo√°n --------
def show_prediction_examples(num_examples=10):
    print("\nüñºÔ∏è ƒêang hi·ªÉn th·ªã m·ªôt v√†i v√≠ d·ª• d·ª± ƒëo√°n...")
    test_ds = datasets.ImageFolder(TEST_DIR, transform=eval_transform)  # S·ª≠ d·ª•ng eval_transform
    # L·∫•y ·∫£nh ng·∫´u nhi√™n ƒë·ªÉ hi·ªÉn th·ªã
    indices = torch.randperm(len(test_ds)).tolist()[:num_examples]
    images = [test_ds[i][0] for i in indices]
    labels = [test_ds[i][1] for i in indices]

    # Chu·∫©n b·ªã tensor ƒë·ªÉ ƒë∆∞a v√†o model
    images_tensor = torch.stack(images).to(device)

    with torch.no_grad():
        outputs = model(images_tensor)
        _, preds = torch.max(outputs, 1)

    # ƒê·ªÉ hi·ªÉn th·ªã, ch√∫ng ta c·∫ßn "un-normalize" ·∫£nh, nh∆∞ng ƒë·ªÉ ƒë∆°n gi·∫£n, ta s·∫Ω hi·ªÉn th·ªã ·∫£nh g·ªëc tr∆∞·ªõc khi transform
    raw_ds = datasets.ImageFolder(TEST_DIR, transform=transforms.Compose([transforms.Resize((224, 224))]))

    plt.figure(figsize=(15, 7))
    for i in range(num_examples):
        plt.subplot(2, 5, i + 1)
        # L·∫•y ·∫£nh g·ªëc ƒë·ªÉ hi·ªÉn th·ªã cho ƒë·∫πp
        raw_img, _ = raw_ds[indices[i]]
        plt.imshow(raw_img)

        true_label = classes[labels[i]]
        pred_label = classes[preds[i]]
        color = "green" if true_label == pred_label else "red"
        plt.title(f"Th·∫≠t: {true_label}\nD·ª± ƒëo√°n: {pred_label}", color=color, fontsize=10)
        plt.axis('off')
    plt.tight_layout()
    plt.show()


# -------- Main Execution --------
if __name__ == "__main__":
    plot_history(history)
    generate_confusion_matrix()
    show_prediction_examples()